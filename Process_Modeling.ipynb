{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import identification as ob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import control as con\n",
    "import warnings\n",
    "import glob #for returning files having the specified path extension\n",
    "import time\n",
    "import statistics as stats\n",
    "import os #checking for empty file\n",
    "import pathlib #for creating new path\n",
    "\n",
    "start_time = list(time.localtime())[5] \n",
    "#returns the local time at the start of execution. Can be used to calculate the execution time manually\n",
    "%pylab inline\n",
    "warnings.filterwarnings('ignore') \n",
    "#ignores all the warnings that may arise during runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Passing all the data into arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_first        = sorted(glob.glob('step_log/*/*task*.log')) #corresponds to .log files that has data related to the first position\n",
    "control_first     = sorted(glob.glob('step_log/*/*control*.log'))\n",
    "task_remaining    = sorted(glob.glob('step_log/*/*task*.log.*')) #corresponds to remaining log.'n' files\n",
    "control_remaining = sorted(glob.glob('step_log/*/*control*.log.*'))\n",
    "task              = sorted(task_first + task_remaining) #set of all task_velocity logs\n",
    "control           = sorted(control_first + control_remaining) #set of all control logs\n",
    "observations      = len(task_first) #total number of experiments conducted/observations taken\n",
    "positions         = int(len(task) / observations) #number of points in the given task space\n",
    "task_full         = [] #A task_velocity list whose each element is a list of similar log files i.e from the same position\n",
    "control_full      = [] #A control_output list whose each element is a list of similar log files i.e from the same position\n",
    "\n",
    "for i in range(0, positions):\n",
    "    task_full.append([])\n",
    "    control_full.append([])\n",
    "    for j in range(0, observations):\n",
    "        task_full[i].append(task[i + (j * positions)])\n",
    "        control_full[i].append(control[i + (j * positions)])\n",
    "\n",
    "count = 0 #counter that returns the number of empty files\n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations):\n",
    "        if os.stat(task_full[i][j]).st_size == 0:\n",
    "            count = count + 1\n",
    "            \n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations-count):\n",
    "        if os.stat(task_full[i][j]).st_size == 0:\n",
    "            del(task_full[i][j])\n",
    "            del(control_full[i][j])\n",
    "            \n",
    "# Reading all the data into a dataframe array\n",
    "df_ist_soll = []\n",
    "for i in range(0, positions):\n",
    "    df_ist_soll.append([])\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            df_ist_soll[i].append(ob.batch_read_data(control_full[i][j], task_full[i][j]))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Manually changing the setpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, observations):\n",
    "    df_ist_soll[0][i].x_soll[df_ist_soll[0][i].x_soll > 0] = 0.15\n",
    "    df_ist_soll[3][i].x_soll[df_ist_soll[3][i].x_soll > 0] = 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Displaying all the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path('Overview/').mkdir(parents = True, exist_ok = True) #The observations are plotted in a folder called Overview\n",
    "for i in range(0, positions):\n",
    "    fig = plt.figure(figsize = (10,30))\n",
    "    fig.suptitle('Position %s'%(i + 1), fontsize = 20, fontweight = 'bold')\n",
    "    for j in range(0, observations): \n",
    "        try:\n",
    "            ax = fig.add_subplot(observations, 1, j + 1)\n",
    "            ax.set_title('Observation %s'%(j + 1))\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.plot(df_ist_soll[i][j]) \n",
    "        except:\n",
    "            pass\n",
    "    plt.savefig('Overview/Position %s.png'%(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "library(stats) \n",
    "#for using the ar() function\n",
    "library(forecast) \n",
    "#for using the fitted.values() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify(df):\n",
    "    #Removing all zeros & the negative trend and reformatting the data in accordance with a unit step response\n",
    "    xin_array, yout_array, t_array = ob.strip_multiply(df) \n",
    "    #The function returns the aic,mse and fitted values for a given output data and a given order \n",
    "    def order_ar_R(ar_order, output):\n",
    "        %R -i ar_order,output \n",
    "        #data is inputed as a list vector. In a list vector, each element in the list is an array. No space can be provided after comma. If provided, it results in 'NameError: name '' is not defined' error.\n",
    "        %R output                 = unlist(output)  \n",
    "        #converts the list vector back into a single array. Need this step in latest R version 3.4.2.\n",
    "        %R ar_system              = ar(output, method = \"ols\", order.max = ar_order)\n",
    "        %R fitted_ar_with_missing = fitted.values(ar_system) \n",
    "        #the lower values in the output data contributes to NA/missing values in the fitted values. This corresponds to the delay in the output data.\n",
    "        %R -o fitted_ar_with_missing\n",
    "\n",
    "        fitted_ar_without_missing = np.nan_to_num(fitted_ar_with_missing) \n",
    "        #the missing values becomes nan values in Python and they are converted to 0. It becomes easier in finding the delay for our model.\n",
    "        mse_ar = mean_squared_error(output,fitted_ar_without_missing)\n",
    "\n",
    "        %R -i mse_ar\n",
    "        %R output_length = length(output) \n",
    "        %R aic_ar        = (output_length * log(mse_ar)) + (2 * ar_order) + (output_length * dim(matrix(output))[2] * (log(2 * pi) + 1)) #result obtained from https://rdrr.io/cran/sysid/src/R/estpoly.R\n",
    "        %R -o aic_ar,mse_ar\n",
    "\n",
    "        return list(aic_ar), mse_ar, fitted_ar_without_missing\n",
    "\n",
    "    order_ar_P = ob.order_ar_P #AR prediction using Python\n",
    "\n",
    "    #The function returns a dataframe that contains the aic,mse and order values from 1 to 10 along with the fitted values for each order \n",
    "    def order_aic_mse_fit(yout):\n",
    "        aic                  = []\n",
    "        order                = []\n",
    "        mse                  = []\n",
    "        fit_values           = []\n",
    "        aic_mse_fit_df       = [] \n",
    "        aic_mse_fit_df.append([])\n",
    "        #2D array in which each element stores two floats(aic and mse) and an array(fit_values)\n",
    "\n",
    "        for i in range(1,11):\n",
    "            order.append(i)\n",
    "            aic_mse_fit_df.append(order_ar_R(i,yout)) #change order_ar_R to order_ar_P to perform AR prediction in Python\n",
    "            aic.append(aic_mse_fit_df[i][0])\n",
    "            mse.append(aic_mse_fit_df[i][1])\n",
    "            fit_values.append(aic_mse_fit_df[i][2])\n",
    "\n",
    "        df = pd.DataFrame(np.column_stack([order, aic, mse]),\\\n",
    "                          columns=['order', 'aic', 'mse']) \n",
    "        #all variables are passed into the dataframe as type float by default  \n",
    "        return df, fit_values\n",
    "\n",
    "\n",
    "    df_fit_array = []\n",
    "    df_array = []\n",
    "    fit_val = []\n",
    "\n",
    "    for i in range(0, len(yout_array)):\n",
    "        df_fit_array.append(order_aic_mse_fit(yout_array[i]))\n",
    "        df_array.append(df_fit_array[i][0])\n",
    "        fit_val.append(df_fit_array[i][1])\n",
    "\n",
    "    #oma_best is an array that contains order, mse and aic values of the best fit data\n",
    "    oma_best    = []\n",
    "    mse_best    = []\n",
    "    aic_best    = []\n",
    "    order_best  = []\n",
    "    fitted_best = []\n",
    "\n",
    "    for i in range(0, len(df_fit_array)):\n",
    "        oma_best.append(list(df_array[i][df_array[i].mse == df_array[i].mse.min()].values[0]))\n",
    "        order_best.append(oma_best[i][0])\n",
    "        mse_best.append(oma_best[i][1])\n",
    "        aic_best.append(oma_best[i][2])    \n",
    "        fitted_best.append(fit_val[i][int(order_best[i]) - 1])    \n",
    "\n",
    "        \n",
    "    '''Smoothing of fitted data'''\n",
    "    smooth_1 = []\n",
    "\n",
    "    for i in range(0, len(fitted_best)):\n",
    "        smooth_1.append(ob.smooth(fitted_best[i], 1))\n",
    "        \n",
    "    \n",
    "    '''PT1 modeling'''\n",
    "    # The steady state value is calculated based on the final values of the step response. \n",
    "    #In case of a faulty step response, the overall model also gets affected. \n",
    "        \n",
    "    #youto,to are the yout and t outputs from the pt1 and pt2 system\n",
    "    #tf and delay are the transfer functions of the output and its delay\n",
    "    #tdytdts is an array that contains all the above values in a sequential order\n",
    "    to_1           = []\n",
    "    tf_1           = []\n",
    "    zeta           = []\n",
    "    youto_1        = []\n",
    "    delay_1        = []\n",
    "    tdytdts_1      = []\n",
    "    delay_tf_1     = []\n",
    "    steady_state_1 = []\n",
    "    time_constant_1 = []\n",
    "    \n",
    "    for i in range(0,len(smooth_1)):\n",
    "        tdytdts_1.append(ob.pt1(smooth_1[i], t_array[i]))\n",
    "        tf_1.append(tdytdts_1[i][0])\n",
    "        youto_1.append(tdytdts_1[i][1])\n",
    "        to_1.append(tdytdts_1[i][2])\n",
    "        delay_1.append(tdytdts_1[i][3])\n",
    "        time_constant_1.append(tdytdts_1[i][4])\n",
    "        steady_state_1.append(tdytdts_1[i][5])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return steady_state_1, time_constant_1, delay_1, xin_array, yout_array, t_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plotting of ideal model from each point in the task space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the timeseries in a position is modeled according to the pt1 modeling and the ideal model \n",
    "# in a position is calculated by taking the average of these individual models.\n",
    "\n",
    "\n",
    "system_matrix = []\n",
    "mean_matrix   = []\n",
    "median_matrix = []\n",
    "std_matrix    = [] # std = standard deviation\n",
    "var_matrix    = [] # var = variance\n",
    "model_pos     = [] # model as time series for each positions\n",
    "yout_full     = []\n",
    "for i in range(0, positions):\n",
    "    try:\n",
    "        steady_state_1, time_constant_1, delay_1, xin_array, yout_array, t_array = identify(df_ist_soll[i])\n",
    "    except:\n",
    "        continue\n",
    "    ideal_tf_pt1, ideal_model_output_pt1, ideal_model_time_pt1 = ob.ideal_pt1(steady_state_1, time_constant_1, delay_1)\n",
    "    yout_full.append(yout_array)\n",
    "    model_pos.append(ideal_model_output_pt1)\n",
    "    mean_matrix.append(stats.mean(ideal_model_output_pt1))\n",
    "    median_matrix.append(stats.median(ideal_model_output_pt1))\n",
    "    std_matrix.append(stats.pstdev(ideal_model_output_pt1))\n",
    "    var_matrix.append(stats.variance(ideal_model_output_pt1))\n",
    "    plt.plot(ideal_model_time_pt1, ideal_model_output_pt1, label = 'position %s ideal model'%(i+1))\n",
    "    plt.legend()\n",
    "    plt.savefig('model.png')\n",
    "    system_matrix.append(ob.ss(ideal_tf_pt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying output on Jupyter\n",
    "\n",
    "#print('\\033[1m' + 'Statistical Information' + '\\033[0m')\n",
    "#for i in range(0, len(model_pos)):\n",
    "#    print('Position %s'%(i+1))\n",
    "#    print('Mean:', mean_matrix[i])\n",
    "#    print('Median:', median_matrix[i])\n",
    "#    print('Standard Deviation:', std_matrix[i])\n",
    "#    print('Variance:', var_matrix[i])\n",
    "#    print('Quantiles[0.25, 0.50, 0.75]:', pd.Series(model_pos[i]).quantile([.25, .5, .75]).values)\n",
    "#    print('Min:', min(model_pos[i]), ',', 'Max:', max(model_pos[i]))\n",
    "#    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Displaying statistical output of each positions in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_matrix = []\n",
    "with open(\"Statistical_Output.txt\", \"w\") as text_file:\n",
    "    print('###########################',            file = text_file)\n",
    "    print('  STATISTICAL INFORMATION  ',            file = text_file)\n",
    "    print('###########################',            file = text_file)\n",
    "    for i in range(0, len(model_pos)):\n",
    "        print('Position %s'%(i+1),                  file = text_file)\n",
    "        print('Mean:', mean_matrix[i],              file = text_file)\n",
    "        print('Median:', median_matrix[i],          file = text_file)\n",
    "        print('Standard Deviation:', std_matrix[i], file = text_file)\n",
    "        print('Variance:', var_matrix[i],           file = text_file)\n",
    "        print('Quantiles[0.25, 0.50, 0.75]:',\\\n",
    "              pd.Series(model_pos[i]).quantile\\\n",
    "              ([.25, .5, .75]).values,              file = text_file)\n",
    "        quant_matrix.append(pd.Series(model_pos[i]).quantile([.25, .5, .75]).values)\n",
    "        print('Min:', min(model_pos[i]), ',',\\\n",
    "              'Max:', max(model_pos[i]),            file = text_file)\n",
    "        print('', file = text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataframe that contains statistical info of all ideal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d    = {'Position': range(1, positions+1), 'Mean': mean_matrix, 'Median': median_matrix, 'Std_Dev': std_matrix,\\\n",
    "     'Variance': var_matrix, 'Quantile': quant_matrix} #variable to pass data \n",
    "cols = ['Position', 'Mean', 'Median',  'Std_Dev', 'Variance', 'Quantile'] #column names\n",
    "df_ideal   = pd.DataFrame(data = d) \n",
    "df_ideal   = df_ideal[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Statistical values of all the ideal models in a textfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"All_Model_Statistical_Output.txt\", \"w\") as text_file:\n",
    "    for i in range(0,positions):\n",
    "        print('Position %s'%(i+1), file = text_file)\n",
    "        print('Obs     ',\\\n",
    "              'Mean              ', \\\n",
    "              'Median            ', \\\n",
    "              'Standard Deviation   ',\\\n",
    "              'Variance                ', \\\n",
    "               'Quantile          ', file = text_file)\n",
    "\n",
    "        for j in range(0,observations):\n",
    "            try:\n",
    "                print('%s'%(j+1),' ',\\\n",
    "                      stats.mean(yout_full[i][j]), ' ',\\\n",
    "                      stats.median(yout_full[i][j]), '    ',\\\n",
    "                      stats.pstdev(yout_full[i][j]), '   ',\\\n",
    "                      stats.variance(yout_full[i][j]), '         ',\\\n",
    "                      pd.Series(yout_full[i][j]).quantile([.25, .5, .75]).values, \\\n",
    "                     file = text_file)\n",
    "            except:\n",
    "                continue\n",
    "        print('', file = text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Statistical values of all the model timeseries in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_matrix = []\n",
    "obs_matrix = []\n",
    "mean_matrix = []\n",
    "median_matrix = []\n",
    "std_matrix = []\n",
    "var_matrix = []\n",
    "quant_matrix = []\n",
    "\n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            pos_matrix.append(i+1)\n",
    "            obs_matrix.append(j+1)\n",
    "            mean_matrix.append(stats.mean(yout_full[i][j]))\n",
    "            median_matrix.append(stats.median(yout_full[i][j]))\n",
    "            std_matrix.append(stats.pstdev(yout_full[i][j]))\n",
    "            var_matrix.append(stats.variance(yout_full[i][j]))\n",
    "            quant_matrix.append(pd.Series(yout_full[i][j]).quantile([.25, .5, .75]).values)\n",
    "        except:\n",
    "            del pos_matrix[-1]\n",
    "            del obs_matrix[-1]\n",
    "            continue\n",
    "\n",
    "d    = {'Position': pos_matrix, 'Observation': obs_matrix, 'Mean': mean_matrix, 'Median': median_matrix, 'Std_Dev': std_matrix,\\\n",
    "     'Variance': var_matrix, 'Quantile': quant_matrix}\n",
    "cols = ['Position', 'Observation', 'Mean', 'Median',  'Std_Dev', 'Variance', 'Quantile']\n",
    "df_all   = pd.DataFrame(data=d)\n",
    "df_all   = df_all[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_time = list(time.localtime())[5]\n",
    "s=np.subtract(end_time, start_time)\n",
    "print('Total execution time is ',abs(s),' seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

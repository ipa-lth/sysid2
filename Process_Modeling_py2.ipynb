{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import identification_py2 as ident_tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import control as con\n",
    "import glob #for returning files having the specified path extension\n",
    "import statistics as stats\n",
    "import os #checking for empty file\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Passing all the data into arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_first        = sorted(glob.glob('step_log_new/*/*task*.log')) #corresponds to .log files that has data related to the first position\n",
    "control_first     = sorted(glob.glob('step_log_new/*/*control*.log'))\n",
    "task_remaining    = sorted(glob.glob('step_log_new/*/*task*.log.*')) #corresponds to remaining log.'n' files\n",
    "control_remaining = sorted(glob.glob('step_log_new/*/*control*.log.*'))\n",
    "task              = sorted(task_first + task_remaining) #set of all task_velocity logs\n",
    "control           = sorted(control_first + control_remaining) #set of all control logs\n",
    "observations      = len(task_first) #total number of experiments conducted/observations taken\n",
    "positions         = int(len(task) / observations) #number of points in the given task space\n",
    "task_full         = [] #A task_velocity list whose each element is a list of similar log files i.e from the same position\n",
    "control_full      = [] #A control_output list whose each element is a list of similar log files i.e from the same position\n",
    "\n",
    "for i in range(0, positions):\n",
    "    task_full.append([])\n",
    "    control_full.append([])\n",
    "    for j in range(0, observations):\n",
    "        task_full[i].append(task[i + (j * positions)])\n",
    "        control_full[i].append(control[i + (j * positions)])\n",
    "\n",
    "count = 0 #counter that returns the number of empty files\n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations):\n",
    "        if os.stat(task_full[i][j]).st_size == 0:\n",
    "            count = count + 1\n",
    "            \n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations-count):\n",
    "        if os.stat(task_full[i][j]).st_size == 0:\n",
    "            del(task_full[i][j])\n",
    "            del(control_full[i][j])\n",
    "            \n",
    "# Reading all the data into a dataframe array\n",
    "df_ist_soll = []\n",
    "model_estimations = []\n",
    "\n",
    "for i in range(0, positions):\n",
    "    df_ist_soll.append([])\n",
    "    model_estimations.append([])\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            # initialize result dictionary\n",
    "            model_estimations[i].append({})\n",
    "            df_ist_soll[i].append(ident_tools.batch_read_data(control_full[i][j], task_full[i][j]))\n",
    "        except:\n",
    "            print \"Some Error occured and was ignored\"\n",
    "            continue\n",
    "            \n",
    "print \"############################### INFO #########################################\"\n",
    "print \"df_ist_soll contains all reference and actual data per each position and each experiement\"\n",
    "print\n",
    "print \"df_ist_soll[position][experiement] -> pandas.Dataframe{'x_ist', 'x_soll'}\"\n",
    "print \"model_estimations[position][experiement] -> dict{'delay', 'scale_factor', ...}\"\n",
    "print \"############################### INFO #########################################\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Manually changing the setpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0, observations):\n",
    "#    df_ist_soll[0][i].x_soll[df_ist_soll[0][i].x_soll > 0] = 0.15\n",
    "#    df_ist_soll[3][i].x_soll[df_ist_soll[3][i].x_soll > 0] = 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Displaying all the observations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The first try except code avoids the errors arising due to the already existing Overview directory. \n",
    "# The second try except code avoids the errors resulting from the plotting of the empty data file \n",
    "try:\n",
    "    os.makedirs('View_Data/')\n",
    "except OSError, e:\n",
    "    if e.errno != os.errno.EEXIST:\n",
    "        raise   \n",
    "    pass\n",
    "\n",
    "for i in range(0, positions):\n",
    "    fig = plt.figure(figsize = (10,30))\n",
    "    fig.suptitle('Position %s'%(i + 1), fontsize = 20, fontweight = 'bold')\n",
    "    for j in range(0, observations): \n",
    "        try:\n",
    "            ax = fig.add_subplot(observations, 1, j + 1)\n",
    "            ax.set_title('Observation %s'%(j + 1))\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.plot(df_ist_soll[i][j]) \n",
    "        except:\n",
    "            pass\n",
    "    plt.savefig('View_Data/Position %s.png'%(i + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Smoothing using Savgol filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_pos in enumerate(df_ist_soll):\n",
    "    for j, df_exp in enumerate(df_pos):\n",
    "        #print (pd.DataFrame(range(0, len(df_exp)), columns=['col1'], index=df_exp.index)).head()\n",
    "        #print df_exp.head()\n",
    "        #print (pd.DataFrame(range(0, len(df_exp)), columns=['col1'], index=df_exp.index)).tail()\n",
    "        #print df_exp.tail()\n",
    "        \n",
    "        # The following expects the unit step to be single and alone per experiement!\n",
    "        if len(df_exp.x_soll.value_counts()) > 2:\n",
    "            print \"WARNING! - Data in Position {0}, Experiement {1} (df_ist_soll[{0}][{1}])\".format(i, j)\n",
    "            print \"has more than {} different values\". format(len(df_exp.x_soll.value_counts()))\n",
    "            print \"!!!! This could lead to wrong calculations!!!!\"\n",
    "            print \"!!!! Target values should be either Zero (beginning) or step height (until end)!!!!\"\n",
    "            print df_exp.x_soll.value_counts()\n",
    "\n",
    "        factor = 1.0/max(df_exp.x_soll)\n",
    "        model_estimations[i][j]['step_height'] = max(df_exp.x_soll)\n",
    "        model_estimations[i][j]['scale_factor'] = factor\n",
    "        df_ist_soll[i][j] = pd.concat(\n",
    "            [df_ist_soll[i][j],\n",
    "            pd.DataFrame(\n",
    "                factor*np.array(df_exp.x_ist),\n",
    "                columns=['normalized'],\n",
    "                index=df_exp.index)],\n",
    "            axis=1)\n",
    "        \n",
    "        for order in range(1, 4):\n",
    "            df_ist_soll[i][j] = pd.concat(\n",
    "                [df_ist_soll[i][j],\n",
    "                pd.DataFrame(\n",
    "                    ident_tools.smooth(factor*np.array(df_exp.x_ist), order),\n",
    "                    columns=['smooth_{}'.format(order)],\n",
    "                    index=df_exp.index)],\n",
    "                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ist_soll[0][0].plot()\n",
    "print df_ist_soll[0][0].head()\n",
    "\n",
    "print model_estimations[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing_sg(yout_array, order):\n",
    "    smoothed = [] #array having values, whoose smoothing is done according to order \n",
    "    \n",
    "    for yout in yout_array:\n",
    "        smoothed.append(ident_tools.smooth(yout, order))\n",
    "\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PT1 Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The steady state value is calculated based on the final values of the step response. \n",
    "#In case of a faulty step response, the overall model also gets affected. \n",
    "\n",
    "#youto,to are the yout and t outputs from the pt1 and pt2 system\n",
    "#tf and delay are the transfer functions of the output and its delay\n",
    "#tdytdts is an array that contains all the above values in a sequential order\n",
    "def pt1(yout_array, t_array):\n",
    "    to_1           = []\n",
    "    tf_1           = []\n",
    "    youto_1        = []\n",
    "    delay_1        = []\n",
    "    tdytdts_1      = []\n",
    "    delay_tf_1     = []\n",
    "    steady_state_1 = []\n",
    "    time_constant_1 = []\n",
    "    smooth_1 = smoothing_sg(yout_array, 1)\n",
    "    #plot(smooth_1[0])\n",
    "    \n",
    "    for i in range(0, len(smooth_1)):\n",
    "        tdytdts_1.append(ident_tools.pt1(smooth_1[i], t_array[i]))\n",
    "        tf_1.append(tdytdts_1[i][0])\n",
    "        youto_1.append(tdytdts_1[i][1])\n",
    "        to_1.append(tdytdts_1[i][2])\n",
    "        delay_1.append(tdytdts_1[i][3])\n",
    "        time_constant_1.append(tdytdts_1[i][4])\n",
    "        steady_state_1.append(tdytdts_1[i][5])\n",
    "    return steady_state_1, time_constant_1, delay_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_pos in enumerate(df_ist_soll):\n",
    "    for j, df_exp in enumerate(df_pos):\n",
    "        \n",
    "        for order in range(1,4):\n",
    "            # PT1 Estimations\n",
    "            tf, _, _, delay, time_constant, steady_state, tf_without_delay =\\\n",
    "                ident_tools.pt1(np.array(df_exp['smooth_{}'.format(order)]), np.array(df_exp.index))\n",
    "            pt1_dict = {\n",
    "                'tf_delay': tf,\n",
    "                'tf': tf_without_delay,\n",
    "                'delay': delay,\n",
    "                'time_constant': time_constant,\n",
    "                'steady_state': steady_state\n",
    "            }\n",
    "            model_estimations[i][j]['pt1_smooth_{}'.format(order)] = pt1_dict\n",
    "        \n",
    "        #for order in range(2,4):\n",
    "            # PT2 Estimations\n",
    "        #order = 2\n",
    "        #tf, _, _, delay, time_constant, steady_state, zeta, tf_without_delay =\\\n",
    "        #    ident_tools.pt2(np.array(df_exp['smooth_{}'.format(order)]), np.array(df_exp.index))\n",
    "\n",
    "        #pt2_dict = {\n",
    "        #    'tf_delay': tf,\n",
    "        #    'tf': tf_without_delay,\n",
    "        #    'delay': delay,\n",
    "        #    'time_constant': time_constant,\n",
    "        #    'steady_state': steady_state,\n",
    "        #    'zeta': zeta,\n",
    "        #}\n",
    "        #model_estimations[i][j]['pt2_smooth_{}'.format(order)] = pt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model_estimations[0][0].keys()\n",
    "print model_estimations[0][0]['pt1_smooth_1'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plotting of ideal pt1 model from each point in the task space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the timeseries in a position is modeled according to the pt1 modeling and the ideal model \n",
    "# in a position is calculated by taking the average of these individual models.\n",
    "\n",
    "\n",
    "system_matrix_pt1  = [] #contains all the state space parameters of all ideal models\n",
    "mean_matrix_pt1    = []\n",
    "median_matrix_pt1  = []\n",
    "std_matrix_pt1     = [] # std = standard deviation\n",
    "var_matrix_pt1     = [] # var = variance\n",
    "model_pos_pt1      = [] # model as time series for each positions\n",
    "yout_full_pt1      = []\n",
    "model_time_pt1     = []\n",
    "model_output_pt1   = []\n",
    "\n",
    "for i in range(0, positions):\n",
    "    try:\n",
    "#        xin_array, yout_array, t_array = ident_tools.strip_multiply(df_ist_soll[i])\n",
    "        xin_array, yout_array, t_array, m_factor = ident_tools.unit_response(df_ist_soll[i])\n",
    "        steady_state_1, time_constant_1, delay_1 = pt1(yout_array, t_array)\n",
    "        \n",
    "        assert(np.allclose(steady_state_1, \n",
    "                           [model_estimations[i][it]['pt1_smooth_1']['steady_state'] for it in range(0, observations)]))\n",
    "        assert(np.allclose(time_constant_1, \n",
    "                           [model_estimations[i][it]['pt1_smooth_1']['time_constant'] for it in range(0, observations)]))\n",
    "        assert(np.allclose(delay_1, \n",
    "                           [model_estimations[i][it]['pt1_smooth_1']['delay'] for it in range(0, observations)]))\n",
    "\n",
    "        ideal_tf_pt1, ideal_model_output_pt1, ideal_model_time_pt1, tf_without_delay_pt1, avg_delay_pt1 = ident_tools.ideal_pt1(steady_state_1, time_constant_1, delay_1)\n",
    "    except Exception, e:\n",
    "        print \"Exception: {}\".format(str(e))\n",
    "    yout_full_pt1.append(yout_array)\n",
    "    model_pos_pt1.append(ideal_model_output_pt1)\n",
    "    mean_matrix_pt1.append(stats.mean(ideal_model_output_pt1))\n",
    "    median_matrix_pt1.append(stats.median(ideal_model_output_pt1))\n",
    "    std_matrix_pt1.append(stats.pstdev(ideal_model_output_pt1))\n",
    "    var_matrix_pt1.append(stats.variance(ideal_model_output_pt1))\n",
    "    plt.plot(ideal_model_time_pt1, ideal_model_output_pt1, label = 'position %s ideal model'%(i+1))\n",
    "    plt.legend()\n",
    "    plt.savefig('model_pt1.png')\n",
    "    model_time_pt1.append(ideal_model_time_pt1)\n",
    "    model_output_pt1.append(ideal_model_output_pt1)    \n",
    "    system_matrix_pt1.append(ident_tools.ss(ideal_tf_pt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PT2 Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PT2 modeling'''\n",
    "def pt2(yout_array, t_array):\n",
    "    to_2            = []\n",
    "    tf_2            = []\n",
    "    zeta            = []\n",
    "    youto_2         = []\n",
    "    delay_2         = []\n",
    "    tdytdts_2       = []\n",
    "    delay_tf_2      = []\n",
    "    steady_state_2  = []\n",
    "    time_constant_2 = []\n",
    "    smooth_2 = smoothing_sg(yout_array, 2)\n",
    "    \n",
    "    try:\n",
    "        for i in range(0,len(smooth_2)):\n",
    "            tdytdts_2.append(ident_tools.pt2(smooth_2[i], t_array[i]))\n",
    "            tf_2.append(tdytdts_2[i][0])\n",
    "            youto_2.append(tdytdts_2[i][1])\n",
    "            to_2.append(tdytdts_2[i][2])\n",
    "            delay_2.append(tdytdts_2[i][3])\n",
    "            time_constant_2.append(tdytdts_2[i][4])\n",
    "            steady_state_2.append(tdytdts_2[i][5])\n",
    "            zeta.append(tdytdts_2[i][6])\n",
    "    except:\n",
    "        pass\n",
    "    return steady_state_2, time_constant_2, delay_2, zeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plotting of ideal pt2 model from each point in the task space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_matrix_pt2    = []\n",
    "mean_matrix_pt2      = []\n",
    "median_matrix_pt2    = []\n",
    "std_matrix_pt2       = [] # std = standard deviation\n",
    "var_matrix_pt2       = [] # var = variance\n",
    "model_pos_pt2        = [] # model as time series for each positions\n",
    "yout_full_pt2        = []\n",
    "model_time_pt2   = []\n",
    "model_output_pt2 = []\n",
    "m_factor_array   = [] # used in model validation while plotting\n",
    "for i in range(0, positions):\n",
    "    try:\n",
    "        #xin_array, yout_array, t_array = ident_tools.strip_multiply(df_ist_soll[i])\n",
    "        xin_array, yout_array, t_array, m_factor = ident_tools.unit_response(df_ist_soll[i])\n",
    "        steady_state_2, time_constant_2, delay_2, zeta = pt2(yout_array, t_array)\n",
    "        ideal_tf_pt2, ideal_model_output_pt2, ideal_model_time_pt2, tf_without_delay_pt2, avg_delay_pt2 = ident_tools.ideal_pt2(steady_state_2, time_constant_2, delay_2, zeta)\n",
    "    except:\n",
    "        continue\n",
    "    yout_full_pt2.append(yout_array)\n",
    "    model_pos_pt2.append(ideal_model_output_pt2)\n",
    "    mean_matrix_pt2.append(stats.mean(ideal_model_output_pt2))\n",
    "    median_matrix_pt2.append(stats.median(ideal_model_output_pt2))\n",
    "    std_matrix_pt2.append(stats.pstdev(ideal_model_output_pt2))\n",
    "    var_matrix_pt2.append(stats.variance(ideal_model_output_pt2))\n",
    "    plt.plot(ideal_model_time_pt2, ideal_model_output_pt2, label = 'position %s ideal model'%(i+1))\n",
    "    plt.legend()\n",
    "    plt.savefig('model_pt2.png')\n",
    "    model_time_pt2.append(ideal_model_time_pt2)\n",
    "    model_output_pt2.append(ideal_model_output_pt2)\n",
    "    m_factor_array.append(mean(m_factor))\n",
    "    system_matrix_pt2.append(ident_tools.ss(ideal_tf_pt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Displaying statistical output of each positions in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_matrix_pt1 = []\n",
    "with open(\"Statistical_Output_pt1.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATISTICAL INFORMATION  \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, len(model_pos_pt1)):\n",
    "        text_file.write('Position %s\\n'%(i+1))\n",
    "        text_file.write('Mean:%s\\n' %mean_matrix_pt1[i])\n",
    "        text_file.write('Median:%s\\n' %median_matrix_pt1[i])\n",
    "        text_file.write('Standard Deviation:{0}\\n' .format(std_matrix_pt1[i]))\n",
    "        text_file.write('Variance:%s\\n' %var_matrix_pt1[i])\n",
    "        text_file.write('Quantiles[0.25, 0.50, 0.75]:%s\\n' \\\n",
    "              %pd.Series(model_pos_pt1[i]).quantile\\\n",
    "              ([.25, .5, .75]).values)\n",
    "        quant_matrix_pt1.append(pd.Series(model_pos_pt1[i]).quantile([.25, .5, .75]).values)\n",
    "        text_file.write('Min:%s\\n' %min(model_pos_pt1[i]))\n",
    "        text_file.write('Max:%s\\n\\n' %max(model_pos_pt1[i]))\n",
    "\n",
    "quant_matrix_pt2 = []\n",
    "with open(\"Statistical_Output_pt2.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATISTICAL INFORMATION  \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, len(model_pos_pt2)):\n",
    "        text_file.write('Position %s\\n'%(i+1))\n",
    "        text_file.write('Mean:%s\\n' %mean_matrix_pt2[i])\n",
    "        text_file.write('Median:%s\\n' %median_matrix_pt2[i])\n",
    "        text_file.write('Standard Deviation:{0}\\n' .format(std_matrix_pt2[i]))\n",
    "        text_file.write('Variance:%s\\n' %var_matrix_pt2[i])\n",
    "        text_file.write('Quantiles[0.25, 0.50, 0.75]:%s\\n' \\\n",
    "              %pd.Series(model_pos_pt2[i]).quantile\\\n",
    "              ([.25, .5, .75]).values)\n",
    "        quant_matrix_pt2.append(pd.Series(model_pos_pt2[i]).quantile([.25, .5, .75]).values)\n",
    "        text_file.write('Min:%s\\n' %min(model_pos_pt2[i]))\n",
    "        text_file.write('Max:%s\\n\\n' %max(model_pos_pt2[i]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataframe that contains statistical info of all ideal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pt1    = {'Position': range(1, positions+1), 'Mean': mean_matrix_pt1, 'Median': median_matrix_pt1, 'Std_Dev': std_matrix_pt1,\\\n",
    "     'Variance': var_matrix_pt1, 'Quantile': quant_matrix_pt1} #variable to pass data \n",
    "cols_pt1 = ['Position', 'Mean', 'Median',  'Std_Dev', 'Variance', 'Quantile'] #column names\n",
    "try:\n",
    "    df_ideal_pt1   = pd.DataFrame(data = d_pt1) \n",
    "except:\n",
    "    pass\n",
    "df_ideal_pt1   = df_ideal_pt1[cols_pt1]\n",
    "\n",
    "d_pt2    = {'Position': range(1, positions+1), 'Mean': mean_matrix_pt2, 'Median': median_matrix_pt2, 'Std_Dev': std_matrix_pt2,\\\n",
    "     'Variance': var_matrix_pt2, 'Quantile': quant_matrix_pt2} #variable to pass data \n",
    "cols_pt2 = ['Position', 'Mean', 'Median',  'Std_Dev', 'Variance', 'Quantile'] #column names\n",
    "try:\n",
    "    df_ideal_pt2   = pd.DataFrame(data = d_pt2) \n",
    "except:\n",
    "    pass\n",
    "df_ideal_pt2   = df_ideal_pt2[cols_pt2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Statistical values of all the ideal models in a textfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"All_Model_Statistical_Output_pt1.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATISTICAL INFORMATION  \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, positions):\n",
    "        text_file.write('\\nPosition %s\\n'%(i+1))\n",
    "        text_file.write('Obs       Mean        Median       Standard Deviation    Variance \\\n",
    "        Quantile[.25, .5, .75]\\n')\n",
    "\n",
    "        for j in range(0, observations):\n",
    "            try:\n",
    "                text_file.write('%s   %s  %s  %s    %s  %s\\n'\\\n",
    "                                %((j+1), stats.mean(yout_full_pt1[i][j]), \\\n",
    "                                  stats.median(yout_full_pt1[i][j]), \\\n",
    "                                  stats.pstdev(yout_full_pt1[i][j]),\\\n",
    "                                  stats.variance(yout_full_pt1[i][j]),pd.Series(yout_full_pt1[i][j]).quantile([.25, .5, .75]).values))             \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "with open(\"All_Model_Statistical_Output_pt2.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATISTICAL INFORMATION  \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, positions):\n",
    "        text_file.write('\\nPosition %s\\n'%(i+1))\n",
    "        text_file.write('Obs       Mean        Median       Standard Deviation    Variance \\\n",
    "        Quantile[.25, .5, .75]\\n')\n",
    "\n",
    "        for j in range(0, observations):\n",
    "            try:\n",
    "                text_file.write('%s   %s  %s  %s    %s  %s\\n'\\\n",
    "                                %((j+1), stats.mean(yout_full_pt2[i][j]), \\\n",
    "                                  stats.median(yout_full_pt2[i][j]), \\\n",
    "                                  stats.pstdev(yout_full_pt2[i][j]),\\\n",
    "                                  stats.variance(yout_full_pt2[i][j]),pd.Series(yout_full_pt2[i][j]).quantile([.25, .5, .75]).values))             \n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Statistical values of all the model timeseries in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_matrix_pt1 = []\n",
    "obs_matrix_pt1 = []\n",
    "mean_matrix_pt1 = []\n",
    "median_matrix_pt1 = []\n",
    "std_matrix_pt1 = []\n",
    "var_matrix_pt1 = []\n",
    "quant_matrix_pt1 = []\n",
    "\n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            pos_matrix_pt1.append(i+1)\n",
    "            obs_matrix_pt1.append(j+1)\n",
    "            mean_matrix_pt1.append(stats.mean(yout_full_pt1[i][j]))\n",
    "            median_matrix_pt1.append(stats.median(yout_full_pt1[i][j]))\n",
    "            std_matrix_pt1.append(stats.pstdev(yout_full_pt1[i][j]))\n",
    "            var_matrix_pt1.append(stats.variance(yout_full_pt1[i][j]))\n",
    "            quant_matrix_pt1.append(pd.Series(yout_full_pt1[i][j]).quantile([.25, .5, .75]).values)\n",
    "        except:\n",
    "            del pos_matrix_pt1[-1]\n",
    "            del obs_matrix_pt1[-1]\n",
    "            continue\n",
    "\n",
    "d_pt1    = {'Position': pos_matrix_pt1, 'Observation': obs_matrix_pt1, 'Mean': mean_matrix_pt1, 'Median': median_matrix_pt1, 'Std_Dev': std_matrix_pt1,\\\n",
    "     'Variance': var_matrix_pt1, 'Quantile': quant_matrix_pt1}\n",
    "cols_pt1 = ['Position', 'Observation', 'Mean', 'Median',  'Std_Dev', 'Variance', 'Quantile']\n",
    "df_all_pt1   = pd.DataFrame(data = d_pt1)\n",
    "df_all_pt1   = df_all_pt1[cols_pt1]\n",
    "\n",
    "pos_matrix_pt2 = []\n",
    "obs_matrix_pt2 = []\n",
    "mean_matrix_pt2 = []\n",
    "median_matrix_pt2 = []\n",
    "std_matrix_pt2 = []\n",
    "var_matrix_pt2 = []\n",
    "quant_matrix_pt2 = []\n",
    "\n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            pos_matrix_pt2.append(i+1)\n",
    "            obs_matrix_pt2.append(j+1)\n",
    "            mean_matrix_pt2.append(stats.mean(yout_full_pt2[i][j]))\n",
    "            median_matrix_pt2.append(stats.median(yout_full_pt2[i][j]))\n",
    "            std_matrix_pt2.append(stats.pstdev(yout_full_pt2[i][j]))\n",
    "            var_matrix_pt2.append(stats.variance(yout_full_pt2[i][j]))\n",
    "            quant_matrix_pt2.append(pd.Series(yout_full_pt2[i][j]).quantile([.25, .5, .75]).values)\n",
    "        except:\n",
    "            del pos_matrix_pt2[-1]\n",
    "            del obs_matrix_pt2[-1]\n",
    "            continue\n",
    "\n",
    "d_pt2    = {'Position': pos_matrix_pt2, 'Observation': obs_matrix_pt2, 'Mean': mean_matrix_pt2, 'Median': median_matrix_pt2, 'Std_Dev': std_matrix_pt2,\\\n",
    "     'Variance': var_matrix_pt2, 'Quantile': quant_matrix_pt2}\n",
    "cols_pt2 = ['Position', 'Observation', 'Mean', 'Median',  'Std_Dev', 'Variance', 'Quantile']\n",
    "df_all_pt2   = pd.DataFrame(data = d_pt2)\n",
    "df_all_pt2   = df_all_pt2[cols_pt2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### State Space Parameters of all the ideal models in a textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"State_Space_Parameters_pt1.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATE SPACE PARAMETERS   \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, positions):\n",
    "        text_file.write('\\nPosition %s\\n'%(i+1))\n",
    "        text_file.write('%s'%system_matrix_pt1[i])\n",
    "        text_file.write('\\n')\n",
    "        \n",
    "with open(\"State_Space_Parameters_pt2.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATE SPACE PARAMETERS   \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, positions):\n",
    "        text_file.write('\\nPosition %s\\n'%(i+1))\n",
    "        text_file.write('%s'%system_matrix_pt2[i])\n",
    "        text_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs('Model_Validation/')\n",
    "except OSError, e:\n",
    "    if e.errno != os.errno.EEXIST:\n",
    "        raise   \n",
    "    pass\n",
    "for i in range(0, positions):\n",
    "    fig = plt.figure(figsize = (5,4))\n",
    "    fig.suptitle('Position %s'%(i + 1), fontsize = 20, fontweight = 'bold')\n",
    "    plt.plot(model_time_pt2[i], model_output_pt2[i], '--r', label = 'ideal pt2 model')\n",
    "    plt.plot(model_time_pt1[i], model_output_pt1[i], '--b', label = 'ideal pt1 model')\n",
    "    plt.legend()\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.plot(df_ist_soll[i][j] * m_factor_array[j]) \n",
    "        except:\n",
    "            pass\n",
    "    plt.savefig('Model_Validation/Position %s model.png'%(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

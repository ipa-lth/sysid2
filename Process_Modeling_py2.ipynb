{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import identification_py2 as ob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import control as con\n",
    "import glob #for returning files having the specified path extension\n",
    "import statistics as stats\n",
    "import os #checking for empty file\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Passing all the data into arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_first        = sorted(glob.glob('step_log_new/*/*task*.log')) #corresponds to .log files that has data related to the first position\n",
    "control_first     = sorted(glob.glob('step_log_new/*/*control*.log'))\n",
    "task_remaining    = sorted(glob.glob('step_log_new/*/*task*.log.*')) #corresponds to remaining log.'n' files\n",
    "control_remaining = sorted(glob.glob('step_log_new/*/*control*.log.*'))\n",
    "task              = sorted(task_first + task_remaining) #set of all task_velocity logs\n",
    "control           = sorted(control_first + control_remaining) #set of all control logs\n",
    "observations      = len(task_first) #total number of experiments conducted/observations taken\n",
    "positions         = int(len(task) / observations) #number of points in the given task space\n",
    "task_full         = [] #A task_velocity list whose each element is a list of similar log files i.e from the same position\n",
    "control_full      = [] #A control_output list whose each element is a list of similar log files i.e from the same position\n",
    "\n",
    "for i in range(0, positions):\n",
    "    task_full.append([])\n",
    "    control_full.append([])\n",
    "    for j in range(0, observations):\n",
    "        task_full[i].append(task[i + (j * positions)])\n",
    "        control_full[i].append(control[i + (j * positions)])\n",
    "\n",
    "count = 0 #counter that returns the number of empty files\n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations):\n",
    "        if os.stat(task_full[i][j]).st_size == 0:\n",
    "            count = count + 1\n",
    "            \n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations-count):\n",
    "        if os.stat(task_full[i][j]).st_size == 0:\n",
    "            del(task_full[i][j])\n",
    "            del(control_full[i][j])\n",
    "            \n",
    "# Reading all the data into a dataframe array\n",
    "df_ist_soll = []\n",
    "for i in range(0, positions):\n",
    "    df_ist_soll.append([])\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            df_ist_soll[i].append(ob.batch_read_data(control_full[i][j], task_full[i][j]))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Manually changing the setpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(0, observations):\n",
    "#    df_ist_soll[0][i].x_soll[df_ist_soll[0][i].x_soll > 0] = 0.15\n",
    "#    df_ist_soll[3][i].x_soll[df_ist_soll[3][i].x_soll > 0] = 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Displaying all the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first try except code avoids the errors arising due to the already existing Overview directory. \n",
    "# The second try except code avoids the errors resulting from the plotting of the empty data file \n",
    "try:\n",
    "    os.makedirs('View_Data/')\n",
    "except OSError, e:\n",
    "    if e.errno != os.errno.EEXIST:\n",
    "        raise   \n",
    "    pass\n",
    "\n",
    "for i in range(0, positions):\n",
    "    fig = plt.figure(figsize = (10,30))\n",
    "    fig.suptitle('Position %s'%(i + 1), fontsize = 20, fontweight = 'bold')\n",
    "    for j in range(0, observations): \n",
    "        try:\n",
    "            ax = fig.add_subplot(observations, 1, j + 1)\n",
    "            ax.set_title('Observation %s'%(j + 1))\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.plot(df_ist_soll[i][j]) \n",
    "        except:\n",
    "            pass\n",
    "    plt.savefig('View_Data/Position %s.png'%(i + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Smoothing using Savgol filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smoothing_sg():\n",
    "    smooth_1 = [] #array having values, whoose smoothing is done according to first order \n",
    "    smooth_2 = [] #array having values, whoose smoothing is done according to second order\n",
    "    \n",
    "    for i in range(0, len(yout_array)):\n",
    "        smooth_1.append(ob.smooth(yout_array[i], 1))\n",
    "        smooth_2.append(ob.smooth(yout_array[i], 2))\n",
    "    return smooth_1, smooth_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PT1 Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The steady state value is calculated based on the final values of the step response. \n",
    "#In case of a faulty step response, the overall model also gets affected. \n",
    "\n",
    "#youto,to are the yout and t outputs from the pt1 and pt2 system\n",
    "#tf and delay are the transfer functions of the output and its delay\n",
    "#tdytdts is an array that contains all the above values in a sequential order\n",
    "def pt1(df):\n",
    "    to_1           = []\n",
    "    tf_1           = []\n",
    "    youto_1        = []\n",
    "    delay_1        = []\n",
    "    tdytdts_1      = []\n",
    "    delay_tf_1     = []\n",
    "    steady_state_1 = []\n",
    "    time_constant_1 = []\n",
    "    smooth_1 = smoothing_sg()[0]\n",
    "    \n",
    "    for i in range(0,len(smooth_1)):\n",
    "        tdytdts_1.append(ob.pt1(smooth_1[i], t_array[i]))\n",
    "        tf_1.append(tdytdts_1[i][0])\n",
    "        youto_1.append(tdytdts_1[i][1])\n",
    "        to_1.append(tdytdts_1[i][2])\n",
    "        delay_1.append(tdytdts_1[i][3])\n",
    "        time_constant_1.append(tdytdts_1[i][4])\n",
    "        steady_state_1.append(tdytdts_1[i][5])\n",
    "    return steady_state_1, time_constant_1, delay_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PT2 Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''PT2 modeling'''\n",
    "def pt2(df):\n",
    "    to_2            = []\n",
    "    tf_2            = []\n",
    "    zeta            = []\n",
    "    youto_2         = []\n",
    "    delay_2         = []\n",
    "    tdytdts_2       = []\n",
    "    delay_tf_2      = []\n",
    "    steady_state_2  = []\n",
    "    time_constant_2 = []\n",
    "    smooth_2 = smoothing_sg()[1]\n",
    "    \n",
    "    try:\n",
    "        for i in range(0,len(smooth_2)):\n",
    "            tdytdts_2.append(ob.pt2(smooth_2[i], t_array[i]))\n",
    "            tf_2.append(tdytdts_2[i][0])\n",
    "            youto_2.append(tdytdts_2[i][1])\n",
    "            to_2.append(tdytdts_2[i][2])\n",
    "            delay_2.append(tdytdts_2[i][3])\n",
    "            time_constant_2.append(tdytdts_2[i][4])\n",
    "            steady_state_2.append(tdytdts_2[i][5])\n",
    "            zeta.append(tdytdts_2[i][6])\n",
    "    except:\n",
    "        pass\n",
    "    return steady_state_2, time_constant_2, delay_2, zeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plotting of ideal pt1 model from each point in the task space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the timeseries in a position is modeled according to the pt1 modeling and the ideal model \n",
    "# in a position is calculated by taking the average of these individual models.\n",
    "\n",
    "\n",
    "system_matrix    = [] #contains all the state space parameters of all ideal models\n",
    "mean_matrix      = []\n",
    "median_matrix    = []\n",
    "std_matrix       = [] # std = standard deviation\n",
    "var_matrix       = [] # var = variance\n",
    "model_pos        = [] # model as time series for each positions\n",
    "yout_full        = []\n",
    "model_time_pt1   = []\n",
    "model_output_pt1 = []\n",
    "\n",
    "for i in range(0, positions):\n",
    "    try:\n",
    "#        xin_array, yout_array, t_array = ob.strip_multiply(df_ist_soll[i])\n",
    "        xin_array, yout_array, t_array, m_factor = ob.unit_response(df_ist_soll[i])\n",
    "        steady_state_1, time_constant_1, delay_1 = pt1(df_ist_soll[i])\n",
    "        ideal_tf_pt1, ideal_model_output_pt1, ideal_model_time_pt1 = ob.ideal_pt1(steady_state_1, time_constant_1, delay_1)\n",
    "    except:\n",
    "        continue\n",
    "    yout_full.append(yout_array)\n",
    "    model_pos.append(ideal_model_output_pt1)\n",
    "    mean_matrix.append(stats.mean(ideal_model_output_pt1))\n",
    "    median_matrix.append(stats.median(ideal_model_output_pt1))\n",
    "    std_matrix.append(stats.pstdev(ideal_model_output_pt1))\n",
    "    var_matrix.append(stats.variance(ideal_model_output_pt1))\n",
    "    plt.plot(ideal_model_time_pt1, ideal_model_output_pt1, label = 'position %s ideal model'%(i+1))\n",
    "    plt.legend()\n",
    "    plt.savefig('model_pt1.png')\n",
    "    model_time_pt1.append(ideal_model_time_pt1)\n",
    "    model_output_pt1.append(ideal_model_output_pt1)    \n",
    "    system_matrix.append(ob.ss(ideal_tf_pt1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plotting of ideal pt2 model from each point in the task space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_matrix    = []\n",
    "mean_matrix      = []\n",
    "median_matrix    = []\n",
    "std_matrix       = [] # std = standard deviation\n",
    "var_matrix       = [] # var = variance\n",
    "model_pos        = [] # model as time series for each positions\n",
    "yout_full        = []\n",
    "model_time_pt2   = []\n",
    "model_output_pt2 = []\n",
    "m_factor_array   = [] # used in model validation while plotting\n",
    "for i in range(0, positions):\n",
    "    try:\n",
    "        #xin_array, yout_array, t_array = ob.strip_multiply(df_ist_soll[i])\n",
    "        xin_array, yout_array, t_array, m_factor = ob.unit_response(df_ist_soll[i])\n",
    "        steady_state_2, time_constant_2, delay_2, zeta = pt2(df_ist_soll[i])\n",
    "        ideal_tf_pt2, ideal_model_output_pt2, ideal_model_time_pt2 = ob.ideal_pt2(steady_state_2, time_constant_2, delay_2, zeta)\n",
    "    except:\n",
    "        continue\n",
    "    yout_full.append(yout_array)\n",
    "    model_pos.append(ideal_model_output_pt2)\n",
    "    mean_matrix.append(stats.mean(ideal_model_output_pt2))\n",
    "    median_matrix.append(stats.median(ideal_model_output_pt2))\n",
    "    std_matrix.append(stats.pstdev(ideal_model_output_pt2))\n",
    "    var_matrix.append(stats.variance(ideal_model_output_pt2))\n",
    "    plt.plot(ideal_model_time_pt2, ideal_model_output_pt2, label = 'position %s ideal model'%(i+1))\n",
    "    plt.legend()\n",
    "    plt.savefig('model_pt2.png')\n",
    "    model_time_pt2.append(ideal_model_time_pt2)\n",
    "    model_output_pt2.append(ideal_model_output_pt2)\n",
    "    m_factor_array.append(mean(m_factor))\n",
    "    system_matrix.append(ob.ss(ideal_tf_pt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Displaying statistical output of each positions in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quant_matrix = []\n",
    "with open(\"Statistical_Output.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATISTICAL INFORMATION  \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, len(model_pos)):\n",
    "        text_file.write('Position %s\\n'%(i+1))\n",
    "        text_file.write('Mean:%s\\n' %mean_matrix[i])\n",
    "        text_file.write('Median:%s\\n' %median_matrix[i])\n",
    "        text_file.write('Standard Deviation:{0}\\n' .format(std_matrix[i]))\n",
    "        text_file.write('Variance:%s\\n' %var_matrix[i])\n",
    "        text_file.write('Quantiles[0.25, 0.50, 0.75]:%s\\n' \\\n",
    "              %pd.Series(model_pos[i]).quantile\\\n",
    "              ([.25, .5, .75]).values)\n",
    "        quant_matrix.append(pd.Series(model_pos[i]).quantile([.25, .5, .75]).values)\n",
    "        text_file.write('Min:%s\\n' %min(model_pos[i]))\n",
    "        text_file.write('Max:%s\\n\\n' %max(model_pos[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataframe that contains statistical info of all ideal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d    = {'Position': range(1, positions+1), 'Mean': mean_matrix, 'Median': median_matrix, 'Std_Dev': std_matrix,\\\n",
    "     'Variance': var_matrix, 'Quantile': quant_matrix} #variable to pass data \n",
    "cols = ['Position', 'Mean', 'Median',  'Std_Dev', 'Variance', 'Quantile'] #column names\n",
    "try:\n",
    "    df_ideal   = pd.DataFrame(data = d) \n",
    "except:\n",
    "    pass\n",
    "df_ideal   = df_ideal[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Statistical values of all the ideal models in a textfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"All_Model_Statistical_Output.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATISTICAL INFORMATION  \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0,positions):\n",
    "        text_file.write('\\nPosition %s\\n'%(i+1))\n",
    "        text_file.write('Obs       Mean        Median       Standard Deviation    Variance \\\n",
    "        Quantile[.25, .5, .75]\\n')\n",
    "\n",
    "        for j in range(0,observations):\n",
    "            try:\n",
    "                text_file.write('%s   %s  %s  %s    %s  %s\\n'\\\n",
    "                                %((j+1), stats.mean(yout_full[i][j]), \\\n",
    "                                  stats.median(yout_full[i][j]), \\\n",
    "                                  stats.pstdev(yout_full[i][j]),\\\n",
    "                                  stats.variance(yout_full[i][j]),pd.Series(yout_full[i][j]).quantile([.25, .5, .75]).values))             \n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Statistical values of all the model timeseries in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_matrix = []\n",
    "obs_matrix = []\n",
    "mean_matrix = []\n",
    "median_matrix = []\n",
    "std_matrix = []\n",
    "var_matrix = []\n",
    "quant_matrix = []\n",
    "\n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            pos_matrix.append(i+1)\n",
    "            obs_matrix.append(j+1)\n",
    "            mean_matrix.append(stats.mean(yout_full[i][j]))\n",
    "            median_matrix.append(stats.median(yout_full[i][j]))\n",
    "            std_matrix.append(stats.pstdev(yout_full[i][j]))\n",
    "            var_matrix.append(stats.variance(yout_full[i][j]))\n",
    "            quant_matrix.append(pd.Series(yout_full[i][j]).quantile([.25, .5, .75]).values)\n",
    "        except:\n",
    "            del pos_matrix[-1]\n",
    "            del obs_matrix[-1]\n",
    "            continue\n",
    "\n",
    "d    = {'Position': pos_matrix, 'Observation': obs_matrix, 'Mean': mean_matrix, 'Median': median_matrix, 'Std_Dev': std_matrix,\\\n",
    "     'Variance': var_matrix, 'Quantile': quant_matrix}\n",
    "cols = ['Position', 'Observation', 'Mean', 'Median',  'Std_Dev', 'Variance', 'Quantile']\n",
    "df_all   = pd.DataFrame(data=d)\n",
    "df_all   = df_all[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### State Space Parameters of all the ideal models in a textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"State_Space_Parameters.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATE SPACE PARAMETERS   \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0,positions):\n",
    "        text_file.write('\\nPosition %s\\n'%(i+1))\n",
    "        text_file.write('%s'%system_matrix[i])\n",
    "        text_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs('Model_Validation/')\n",
    "except OSError, e:\n",
    "    if e.errno != os.errno.EEXIST:\n",
    "        raise   \n",
    "    pass\n",
    "for i in range(0, positions):\n",
    "    fig = plt.figure(figsize = (5,4))\n",
    "    fig.suptitle('Position %s'%(i + 1), fontsize = 20, fontweight = 'bold')\n",
    "    plt.plot(model_time_pt2[i], model_output_pt2[i], '--r', label = 'ideal pt2 model')\n",
    "    plt.plot(model_time_pt1[i], model_output_pt1[i], '--b', label = 'ideal pt1 model')\n",
    "    plt.legend()\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.plot(df_ist_soll[i][j] * m_factor_array[j]) \n",
    "        except:\n",
    "            pass\n",
    "    plt.savefig('Model_Validation/Position %s model.png'%(i+1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
